{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1' # specify GPUs locally\n",
    "\n",
    "# libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import albumentations\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset\n",
    "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, ToTensor\n",
    "\n",
    "# from apex import amp # I cannot install apex in Kagggle notebook\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "setting_json = open(\"SETTINGS.json\", \"r\")\n",
    "setting_json = json.load(setting_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OUTPUT': './output',\n",
       " 'INPUT': '../input/rsna-str-pulmonary-embolism-detection',\n",
       " 'TRAIN_IMAGES': '../input/rsna-str-pulmonary-embolism-detection/train-jpegs',\n",
       " 'EXTERNAL': '../input/external_table_data'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG = True\n",
    "\n",
    "kernel_type = 'monai3d_160_3ch_1e-5_20ep_aug'\n",
    "\n",
    "image_size = 100\n",
    "use_amp = False\n",
    "data_dir = f'{setting_json[\"TRAIN_IMAGES\"]}/'\n",
    "num_workers = 8\n",
    "init_lr = 1e-5\n",
    "out_dim = 6\n",
    "freeze_epo = 0\n",
    "warmup_epo = 1\n",
    "cosine_epo = 12\n",
    "n_epochs = freeze_epo + warmup_epo + cosine_epo\n",
    "setting_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [\n",
    "        'rv_lv_ratio_gte_1', # exam level\n",
    "        \"central_pe\",\n",
    "        \"leftsided_pe\",\n",
    "        \"rightsided_pe\",\n",
    "        \"acute_and_chronic_pe\",\n",
    "        \"chronic_pe\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_pickle(f'{setting_json[\"EXTERNAL\"]}/train_with_position.pkl')\n",
    "traindf = traindf.sort_values(['StudyInstanceUID', 'z_pos'])\n",
    "traindf = traindf[(traindf.negative_exam_for_pe == 0) & (traindf.indeterminate == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = traindf[[\"StudyInstanceUID\", \"SeriesInstanceUID\", 'rv_lv_ratio_gte_1', # exam level\n",
    "        \"central_pe\",\n",
    "        \"leftsided_pe\",\n",
    "        \"rightsided_pe\",\n",
    "        \"acute_and_chronic_pe\",\n",
    "        \"chronic_pe\"]].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = pd.merge(grouped, pd.read_csv(f\"{setting_json[\"INPUT\"]}/split.csv\"), on = \"StudyInstanceUID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from monai.transforms import LoadNifti, Randomizable, apply_transform\n",
    "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, ToTensor, RandAffine\n",
    "from monai.utils import get_seed\n",
    "\n",
    "class RSNADataset3D(torch.utils.data.Dataset, Randomizable):\n",
    "    def __init__(self, csv, mode, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "    \n",
    "    def randomize(self) -> None:\n",
    "        MAX_SEED = np.iinfo(np.uint32).max + 1\n",
    "        self._seed = self.R.randint(MAX_SEED, dtype=\"uint32\")    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            self.randomize()\n",
    "            row = self.csv.iloc[index]\n",
    "            #print(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID))\n",
    "            jpg_lst = sorted(glob(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID, '*.png')))\n",
    "\n",
    "            jpg_lst = jpg_lst[int(len(jpg_lst) * 0.25 ): int(len(jpg_lst) * 0.75)]\n",
    "\n",
    "            #print(jpg_lst[len()])\n",
    "            img_lst = [cv2.imread(jpg)[75:425,75:425,::-1] for jpg in jpg_lst] \n",
    "            img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                if isinstance(self.transform, Randomizable):\n",
    "                    self.transform.set_random_state(seed=self._seed)\n",
    "                img = apply_transform(self.transform, img)\n",
    "\n",
    "            if self.mode == 'test':\n",
    "                return img\n",
    "            else:\n",
    "                return img, torch.tensor(row[target_cols]).float()\n",
    "        except:\n",
    "            self.randomize()\n",
    "            row = self.csv.iloc[0]\n",
    "            #print(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID))\n",
    "            jpg_lst = sorted(glob(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID, '*.png')))\n",
    "\n",
    "            jpg_lst = jpg_lst[int(len(jpg_lst) * 0.25 ): int(len(jpg_lst) * 0.75)]\n",
    "\n",
    "            #print(jpg_lst[len()])\n",
    "            img_lst = [cv2.imread(jpg)[100:400,100:400,::-1] for jpg in jpg_lst] \n",
    "            img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                if isinstance(self.transform, Randomizable):\n",
    "                    self.transform.set_random_state(seed=self._seed)\n",
    "                img = apply_transform(self.transform, img)\n",
    "\n",
    "            if self.mode == 'test':\n",
    "                return img\n",
    "            else:\n",
    "                return img, torch.tensor(row[target_cols]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([ScaleIntensity(), \n",
    "                            Resize((image_size, image_size, image_size)), \n",
    "                            RandAffine( \n",
    "                                      prob=0.6,\n",
    "                                      translate_range=(10, 10, 10),\n",
    "                                      rotate_range=(0, 0, 0.2),\n",
    "                                      scale_range=(0.2, 0.2, 0.2),\n",
    "                                      padding_mode='border'),\n",
    "                            ToTensor()])\n",
    "val_transforms = Compose([ScaleIntensity(), Resize((image_size, image_size, image_size)), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.Tensor([1.0686+ 0.3562, 0.8549, 0.2850, 0.2850, 0.4749, 0.4749])\n",
    "bce = nn.BCEWithLogitsLoss(w.cuda())\n",
    "def criterion(logits, target): \n",
    "    loss = bce(logits, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for (data, target) in bar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)       \n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        if not use_amp:\n",
    "            loss.backward()\n",
    "        else:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n",
    "        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def val_epoch(model, loader, is_ext=None, n_test=1, get_output=False):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    LOGITS = []\n",
    "    TARGETS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data)\n",
    "            LOGITS.append(logits.detach().cpu())\n",
    "            TARGETS.append(target.detach().cpu())\n",
    "\n",
    "    val_loss = criterion(torch.cat(LOGITS).cuda(), torch.cat(TARGETS).cuda()).cpu().detach().numpy()\n",
    "    PROBS = torch.sigmoid(torch.cat(LOGITS)).numpy().squeeze()    \n",
    "    LOGITS = torch.cat(LOGITS).numpy()\n",
    "    TARGETS = torch.cat(TARGETS).numpy()\n",
    "    \n",
    "    #for i in range(6):\n",
    "    #    print(target_cols[i], \"mean unweighted logloss: \", log_loss(TARGETS[:, i], np.repeat(grouped[grouped.fold == 1][target_cols[3]].values.mean(), len(grouped[grouped.fold == 1][target_cols[3]].values))), \"unweighted logloss:\", log_loss(TARGETS[:, i], PROBS[:, i]), \"roc_auc:\",  roc_auc_score(TARGETS[:, i], PROBS[:, i]))\n",
    "    for i in range(6):\n",
    "        try:\n",
    "            print(target_cols[i], \"unweighted logloss:\", log_loss(TARGETS[:, i], PROBS[:, i]), \"roc_auc:\",  roc_auc_score(TARGETS[:, i], PROBS[:, i]))\n",
    "        except:\n",
    "            continue\n",
    "    if get_output:\n",
    "        return LOGITS, PROBS, TARGETS\n",
    "    else:\n",
    "        acc = (PROBS.round() == TARGETS).mean() * 100.\n",
    "        auc = roc_auc_score(TARGETS, LOGITS)\n",
    "        return float(val_loss), acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "    df_train = grouped[(grouped['fold'] != fold)]\n",
    "    df_valid = grouped[(grouped['fold'] == fold)]\n",
    "\n",
    "    dataset_train = RSNADataset3D(df_train, 'train', transform=train_transforms)\n",
    "    dataset_valid = RSNADataset3D(df_valid, 'val', transform=val_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=8, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=8, num_workers=num_workers)\n",
    "\n",
    "    model = monai.networks.nets.densenet.densenet121(spatial_dims=3, in_channels=3, out_channels=out_dim).to(device)\n",
    "\n",
    "    val_loss_best = 1000\n",
    "    model_file = f'{kernel_type}_6targets_{fold}.pth'\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=init_lr)\n",
    "    if use_amp:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "#     if len(os.environ['CUDA_VISIBLE_DEVICES'].split(',')) > 1:\n",
    "#         model = nn.DataParallel(model)         \n",
    "        \n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, cosine_epo)\n",
    "    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "        scheduler_warmup.step(epoch-1)\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer)\n",
    "        val_loss, acc, auc = val_epoch(model, valid_loader)\n",
    "    \n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, valid loss: {(val_loss):.5f}, acc: {(acc):.4f}, auc: {(auc):.6f}'\n",
    "        print(content)\n",
    "        with open(f'log_{kernel_type}.txt', 'a') as appender:\n",
    "            appender.write(content + '\\n')             \n",
    "            \n",
    "        torch.save(model.state_dict(), model_file[:-4] + \"_\" + str(val_loss) + \".pth\")\n",
    "        #if val_loss < val_loss_best:\n",
    "        #    print('val_loss_best ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_best, val_loss))\n",
    "        #    torch.save(model.state_dict(), model_file[:-4] + \"_\" + str(val_loss) + \".pth\")\n",
    "        #    val_loss_best = val_loss\n",
    "\n",
    "    torch.save(model.state_dict(), f'{kernel_type}_model_fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1769 442\n",
      "Mon Oct 19 22:45:47 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.31577, smth: 0.37155: 100%|██████████| 222/222 [17:36<00:00,  4.76s/it]\n",
      "100%|██████████| 56/56 [04:18<00:00,  4.62s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6806042518685845 roc_auc: 0.6022291666666666\n",
      "central_pe unweighted logloss: 0.5100659811995688 roc_auc: 0.6107839704618518\n",
      "leftsided_pe unweighted logloss: 0.6114190454127023 roc_auc: 0.5224942456580874\n",
      "rightsided_pe unweighted logloss: 0.5233248228805637 roc_auc: 0.5408682568482542\n",
      "acute_and_chronic_pe unweighted logloss: 0.5205205506329084 roc_auc: 0.4656424814227269\n",
      "chronic_pe unweighted logloss: 0.4348298086030451 roc_auc: 0.4953945596552653\n",
      "Mon Oct 19 23:07:42 2020 Fold 0, Epoch 1, lr: 0.0000100, train loss: 0.39398, valid loss: 0.36381, acc: 79.9397, auc: 0.539569\n",
      "Mon Oct 19 23:07:42 2020 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.39422, smth: 0.32498: 100%|██████████| 222/222 [17:28<00:00,  4.72s/it]\n",
      "100%|██████████| 56/56 [04:15<00:00,  4.57s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:942: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.9042386471275956 roc_auc: 0.591\n",
      "central_pe unweighted logloss: 0.5680588208543499 roc_auc: 0.5978292007511857\n",
      "leftsided_pe unweighted logloss: 0.58315013601904 roc_auc: 0.5648932831136221\n",
      "rightsided_pe unweighted logloss: 0.3950601653849108 roc_auc: 0.5721555958755586\n",
      "acute_and_chronic_pe unweighted logloss: 0.24984112321462365 roc_auc: 0.4516990899223512\n",
      "chronic_pe unweighted logloss: 0.38222323619334947 roc_auc: 0.5332076488015082\n",
      "Mon Oct 19 23:29:27 2020 Fold 0, Epoch 2, lr: 0.0001000, train loss: 0.33094, valid loss: 0.39216, acc: 77.3002, auc: 0.551797\n",
      "Mon Oct 19 23:29:27 2020 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.24808, smth: 0.32111: 100%|██████████| 222/222 [17:35<00:00,  4.75s/it]\n",
      "100%|██████████| 56/56 [04:14<00:00,  4.55s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.8823113862601029 roc_auc: 0.6251041666666667\n",
      "central_pe unweighted logloss: 0.6127854333136955 roc_auc: 0.6014259795652035\n",
      "leftsided_pe unweighted logloss: 0.5776201120463971 roc_auc: 0.5657302783008997\n",
      "rightsided_pe unweighted logloss: 0.4100134125868558 roc_auc: 0.5538788334734699\n",
      "acute_and_chronic_pe unweighted logloss: 0.24387428932717886 roc_auc: 0.5157384987893463\n",
      "chronic_pe unweighted logloss: 0.35899809962854934 roc_auc: 0.524535416105575\n",
      "Mon Oct 19 23:51:17 2020 Fold 0, Epoch 3, lr: 0.0001000, train loss: 0.31773, valid loss: 0.39146, acc: 76.3198, auc: 0.564402\n",
      "Mon Oct 19 23:51:17 2020 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.50182, smth: 0.30580: 100%|██████████| 222/222 [17:23<00:00,  4.70s/it]\n",
      "100%|██████████| 56/56 [04:16<00:00,  4.57s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6273858396724136 roc_auc: 0.7048749999999999\n",
      "central_pe unweighted logloss: 0.4985640581098819 roc_auc: 0.6884807588248401\n",
      "leftsided_pe unweighted logloss: 0.5661309052814995 roc_auc: 0.6246076585059637\n",
      "rightsided_pe unweighted logloss: 0.3982914157919754 roc_auc: 0.6394211621011638\n",
      "acute_and_chronic_pe unweighted logloss: 0.24101437305045478 roc_auc: 0.5856224430157803\n",
      "chronic_pe unweighted logloss: 0.34019383375124157 roc_auc: 0.5501750605978992\n",
      "Tue Oct 20 00:12:57 2020 Fold 0, Epoch 4, lr: 0.0000933, train loss: 0.30692, valid loss: 0.31183, acc: 81.2594, auc: 0.632197\n",
      "Tue Oct 20 00:12:57 2020 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.46730, smth: 0.30143: 100%|██████████| 222/222 [17:27<00:00,  4.72s/it]\n",
      "100%|██████████| 56/56 [04:14<00:00,  4.55s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6764236183592637 roc_auc: 0.5952708333333334\n",
      "central_pe unweighted logloss: 0.5922055346427729 roc_auc: 0.6482477639494542\n",
      "leftsided_pe unweighted logloss: 0.593967051628758 roc_auc: 0.5450408035153798\n",
      "rightsided_pe unweighted logloss: 0.39859931320963404 roc_auc: 0.5810063282736646\n",
      "acute_and_chronic_pe unweighted logloss: 0.23843754791734714 roc_auc: 0.6071637304834265\n",
      "chronic_pe unweighted logloss: 0.355962562614976 roc_auc: 0.5598707244815513\n",
      "Tue Oct 20 00:34:39 2020 Fold 0, Epoch 5, lr: 0.0000854, train loss: 0.30026, valid loss: 0.33920, acc: 80.3167, auc: 0.589433\n",
      "Tue Oct 20 00:34:39 2020 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.55793, smth: 0.28629: 100%|██████████| 222/222 [17:45<00:00,  4.80s/it]\n",
      "100%|██████████| 56/56 [04:13<00:00,  4.53s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5501143449319029 roc_auc: 0.7702916666666667\n",
      "central_pe unweighted logloss: 0.4440602002690685 roc_auc: 0.741382054301811\n",
      "leftsided_pe unweighted logloss: 0.5547874237819495 roc_auc: 0.6506068215107763\n",
      "rightsided_pe unweighted logloss: 0.38005365765910615 roc_auc: 0.6438907819622073\n",
      "acute_and_chronic_pe unweighted logloss: 0.2412009834484682 roc_auc: 0.5678383568506303\n",
      "chronic_pe unweighted logloss: 0.3657232379178386 roc_auc: 0.5312146512254242\n",
      "Tue Oct 20 00:56:38 2020 Fold 0, Epoch 6, lr: 0.0000750, train loss: 0.29288, valid loss: 0.28635, acc: 82.5792, auc: 0.650871\n",
      "Tue Oct 20 00:56:38 2020 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.26143, smth: 0.27066: 100%|██████████| 222/222 [17:33<00:00,  4.75s/it]\n",
      "100%|██████████| 56/56 [04:17<00:00,  4.61s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5465780473261549 roc_auc: 0.8081041666666666\n",
      "central_pe unweighted logloss: 0.4577794923000375 roc_auc: 0.7623579590667473\n",
      "leftsided_pe unweighted logloss: 0.5446531583230555 roc_auc: 0.6926919857710818\n",
      "rightsided_pe unweighted logloss: 0.40045587629147245 roc_auc: 0.5965393636323405\n",
      "acute_and_chronic_pe unweighted logloss: 0.24063713072769646 roc_auc: 0.5869583368122233\n",
      "chronic_pe unweighted logloss: 0.37236201115862816 roc_auc: 0.5570158901158093\n",
      "Tue Oct 20 01:18:30 2020 Fold 0, Epoch 7, lr: 0.0000629, train loss: 0.27902, valid loss: 0.28843, acc: 82.5792, auc: 0.667278\n",
      "Tue Oct 20 01:18:30 2020 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.19423, smth: 0.27334: 100%|██████████| 222/222 [17:25<00:00,  4.71s/it]\n",
      "100%|██████████| 56/56 [04:15<00:00,  4.56s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5088915176757051 roc_auc: 0.8246666666666665\n",
      "central_pe unweighted logloss: 0.40514503036282234 roc_auc: 0.801604227010854\n",
      "leftsided_pe unweighted logloss: 0.5258036227643962 roc_auc: 0.7278980958359489\n",
      "rightsided_pe unweighted logloss: 0.39109493981903565 roc_auc: 0.5927778023631455\n",
      "acute_and_chronic_pe unweighted logloss: 0.24381122607906344 roc_auc: 0.5516406445687568\n",
      "chronic_pe unweighted logloss: 0.34517240145020356 roc_auc: 0.6124427686506868\n",
      "Tue Oct 20 01:40:11 2020 Fold 0, Epoch 8, lr: 0.0000500, train loss: 0.27329, valid loss: 0.26874, acc: 83.6350, auc: 0.685172\n",
      "Tue Oct 20 01:40:12 2020 Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.34022, smth: 0.26745: 100%|██████████| 222/222 [17:43<00:00,  4.79s/it]\n",
      "100%|██████████| 56/56 [04:13<00:00,  4.52s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5066212363187139 roc_auc: 0.8173958333333332\n",
      "central_pe unweighted logloss: 0.4024632984150214 roc_auc: 0.8168825794951777\n",
      "leftsided_pe unweighted logloss: 0.5366489067125846 roc_auc: 0.6894747855199832\n",
      "rightsided_pe unweighted logloss: 0.3794827627047593 roc_auc: 0.6378722839314953\n",
      "acute_and_chronic_pe unweighted logloss: 0.24055200757045822 roc_auc: 0.5784420138598982\n",
      "chronic_pe unweighted logloss: 0.3331952591961865 roc_auc: 0.6111500134661998\n",
      "Tue Oct 20 02:02:08 2020 Fold 0, Epoch 9, lr: 0.0000371, train loss: 0.26692, valid loss: 0.26658, acc: 83.8612, auc: 0.691870\n",
      "Tue Oct 20 02:02:08 2020 Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.47639, smth: 0.25981: 100%|██████████| 222/222 [17:06<00:00,  4.62s/it]\n",
      "100%|██████████| 56/56 [04:11<00:00,  4.48s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5322820948335717 roc_auc: 0.8077083333333335\n",
      "central_pe unweighted logloss: 0.40319358931150606 roc_auc: 0.7964159531463856\n",
      "leftsided_pe unweighted logloss: 0.5383937976563273 roc_auc: 0.6763444235195648\n",
      "rightsided_pe unweighted logloss: 0.38150711501927465 roc_auc: 0.6100809842014427\n",
      "acute_and_chronic_pe unweighted logloss: 0.24197837287703386 roc_auc: 0.5673373966769641\n",
      "chronic_pe unweighted logloss: 0.3398046464537064 roc_auc: 0.5953676272555886\n",
      "Tue Oct 20 02:23:26 2020 Fold 0, Epoch 10, lr: 0.0000250, train loss: 0.25865, valid loss: 0.27359, acc: 83.6350, auc: 0.675542\n",
      "Tue Oct 20 02:23:26 2020 Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.21589, smth: 0.24152: 100%|██████████| 222/222 [17:28<00:00,  4.72s/it]\n",
      "100%|██████████| 56/56 [04:12<00:00,  4.51s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5089091098913712 roc_auc: 0.8344583333333333\n",
      "central_pe unweighted logloss: 0.43684472519497713 roc_auc: 0.7785912085813413\n",
      "leftsided_pe unweighted logloss: 0.5386310818761048 roc_auc: 0.7125706214689266\n",
      "rightsided_pe unweighted logloss: 0.3916593160463404 roc_auc: 0.5687038102402973\n",
      "acute_and_chronic_pe unweighted logloss: 0.24302111553845768 roc_auc: 0.57293145194957\n",
      "chronic_pe unweighted logloss: 0.34258504921561994 roc_auc: 0.5953137624562349\n",
      "Tue Oct 20 02:45:07 2020 Fold 0, Epoch 11, lr: 0.0000146, train loss: 0.24699, valid loss: 0.27363, acc: 83.2579, auc: 0.677095\n",
      "Tue Oct 20 02:45:07 2020 Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.28144, smth: 0.24404: 100%|██████████| 222/222 [17:20<00:00,  4.69s/it]\n",
      "100%|██████████| 56/56 [04:15<00:00,  4.57s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.4832089225491888 roc_auc: 0.8443124999999999\n",
      "central_pe unweighted logloss: 0.40062560814609793 roc_auc: 0.8122354139478626\n",
      "leftsided_pe unweighted logloss: 0.5262255715248407 roc_auc: 0.7101642603055032\n",
      "rightsided_pe unweighted logloss: 0.38314950275888066 roc_auc: 0.6053015887064653\n",
      "acute_and_chronic_pe unweighted logloss: 0.24354821642886054 roc_auc: 0.5591550471737496\n",
      "chronic_pe unweighted logloss: 0.3422617382386792 roc_auc: 0.601992997576084\n",
      "Tue Oct 20 03:06:43 2020 Fold 0, Epoch 12, lr: 0.0000067, train loss: 0.24095, valid loss: 0.26139, acc: 83.7858, auc: 0.688860\n",
      "Tue Oct 20 03:06:43 2020 Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.25932, smth: 0.23892: 100%|██████████| 222/222 [17:29<00:00,  4.73s/it]\n",
      "100%|██████████| 56/56 [04:15<00:00,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.48821599758335504 roc_auc: 0.8415833333333333\n",
      "central_pe unweighted logloss: 0.4023042164176146 roc_auc: 0.8089569341439348\n",
      "leftsided_pe unweighted logloss: 0.5296060120037913 roc_auc: 0.7091441724210085\n",
      "rightsided_pe unweighted logloss: 0.3843601661106378 roc_auc: 0.6020710713811567\n",
      "acute_and_chronic_pe unweighted logloss: 0.24361813076396738 roc_auc: 0.5527260582783668\n",
      "chronic_pe unweighted logloss: 0.34405514012971616 roc_auc: 0.6068408295179101\n",
      "Tue Oct 20 03:28:29 2020 Fold 0, Epoch 13, lr: 0.0000017, train loss: 0.23825, valid loss: 0.26318, acc: 83.9744, auc: 0.686887\n"
     ]
    }
   ],
   "source": [
    "run(fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768 443\n",
      "Tue Oct 20 03:28:30 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.37786, smth: 0.38235: 100%|██████████| 221/221 [17:15<00:00,  4.69s/it]\n",
      "100%|██████████| 56/56 [04:16<00:00,  4.58s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6805717870424887 roc_auc: 0.5937848210969419\n",
      "central_pe unweighted logloss: 0.533625132276027 roc_auc: 0.5813639912000568\n",
      "leftsided_pe unweighted logloss: 0.6115618692563835 roc_auc: 0.5396940097677664\n",
      "rightsided_pe unweighted logloss: 0.5129201087268158 roc_auc: 0.5102642665645347\n",
      "acute_and_chronic_pe unweighted logloss: 0.45027272998613915 roc_auc: 0.5784528656435953\n",
      "chronic_pe unweighted logloss: 0.5021545215600232 roc_auc: 0.5484693877551019\n",
      "Tue Oct 20 03:50:02 2020 Fold 1, Epoch 1, lr: 0.0000100, train loss: 0.40502, valid loss: 0.36644, acc: 79.3830, auc: 0.558672\n",
      "Tue Oct 20 03:50:02 2020 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.39083, smth: 0.32403: 100%|██████████| 221/221 [17:09<00:00,  4.66s/it]\n",
      "100%|██████████| 56/56 [04:15<00:00,  4.57s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:942: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6518256874843322 roc_auc: 0.6679460195617184\n",
      "central_pe unweighted logloss: 0.4584360002470676 roc_auc: 0.6592860691221347\n",
      "leftsided_pe unweighted logloss: 0.5979363064262722 roc_auc: 0.5456742748928536\n",
      "rightsided_pe unweighted logloss: 0.4444561464960096 roc_auc: 0.5379548065875144\n",
      "acute_and_chronic_pe unweighted logloss: 0.2532316930255691 roc_auc: 0.5548073911681805\n",
      "chronic_pe unweighted logloss: 0.3581777826523404 roc_auc: 0.5424669867947178\n",
      "Tue Oct 20 04:11:27 2020 Fold 1, Epoch 2, lr: 0.0001000, train loss: 0.32985, valid loss: 0.31801, acc: 80.5493, auc: 0.584689\n",
      "Tue Oct 20 04:11:27 2020 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.29135, smth: 0.31149: 100%|██████████| 221/221 [17:13<00:00,  4.67s/it]\n",
      "100%|██████████| 56/56 [04:18<00:00,  4.61s/it]\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6302818749930381 roc_auc: 0.7033758408650077\n",
      "central_pe unweighted logloss: 0.4133130196801494 roc_auc: 0.7277694982613016\n",
      "leftsided_pe unweighted logloss: 0.5890918826646514 roc_auc: 0.5906757699591348\n",
      "rightsided_pe unweighted logloss: 0.41826866320323863 roc_auc: 0.6590961317502873\n",
      "acute_and_chronic_pe unweighted logloss: 0.25647651691738155 roc_auc: 0.49295333542123393\n",
      "chronic_pe unweighted logloss: 0.3860929616754265 roc_auc: 0.5095538215286115\n",
      "Tue Oct 20 04:32:59 2020 Fold 1, Epoch 3, lr: 0.0001000, train loss: 0.31811, valid loss: 0.30727, acc: 80.7374, auc: 0.613904\n",
      "Tue Oct 20 04:32:59 2020 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.26131, smth: 0.30493: 100%|██████████| 221/221 [17:17<00:00,  4.69s/it]\n",
      "100%|██████████| 56/56 [04:15<00:00,  4.55s/it]\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.7106921972841461 roc_auc: 0.6840411043704346\n",
      "central_pe unweighted logloss: 0.4222893925640169 roc_auc: 0.7248243559718969\n",
      "leftsided_pe unweighted logloss: 0.6188587428198845 roc_auc: 0.5271852885477923\n",
      "rightsided_pe unweighted logloss: 0.4502262655544698 roc_auc: 0.5968977403293757\n",
      "acute_and_chronic_pe unweighted logloss: 0.2523745350606958 roc_auc: 0.5616974632007516\n",
      "chronic_pe unweighted logloss: 0.39254111996757257 roc_auc: 0.5588735494197679\n",
      "Tue Oct 20 04:54:31 2020 Fold 1, Epoch 4, lr: 0.0000933, train loss: 0.30557, valid loss: 0.33076, acc: 79.3454, auc: 0.608920\n",
      "Tue Oct 20 04:54:31 2020 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.29367, smth: 0.30213: 100%|██████████| 221/221 [17:14<00:00,  4.68s/it]\n",
      "100%|██████████| 56/56 [04:08<00:00,  4.44s/it]\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5744701701870217 roc_auc: 0.7633403491395321\n",
      "central_pe unweighted logloss: 0.4705363010092056 roc_auc: 0.7401887729756582\n",
      "leftsided_pe unweighted logloss: 0.5905161590376369 roc_auc: 0.5882338283663909\n",
      "rightsided_pe unweighted logloss: 0.4276667114549041 roc_auc: 0.6066066641133665\n",
      "acute_and_chronic_pe unweighted logloss: 0.2550885103912036 roc_auc: 0.5719542749765112\n",
      "chronic_pe unweighted logloss: 0.35857938145945356 roc_auc: 0.5733793517406963\n",
      "Tue Oct 20 05:15:55 2020 Fold 1, Epoch 5, lr: 0.0000854, train loss: 0.29524, valid loss: 0.30040, acc: 80.7750, auc: 0.640614\n",
      "Tue Oct 20 05:15:55 2020 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.35602, smth: 0.28280: 100%|██████████| 221/221 [16:49<00:00,  4.57s/it]\n",
      "100%|██████████| 56/56 [04:09<00:00,  4.45s/it]\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5445962299248014 roc_auc: 0.7796830506376131\n",
      "central_pe unweighted logloss: 0.40902974645756435 roc_auc: 0.7586402668369882\n",
      "leftsided_pe unweighted logloss: 0.581936016636764 roc_auc: 0.604405461975481\n",
      "rightsided_pe unweighted logloss: 0.4248130954129298 roc_auc: 0.5952508617387974\n",
      "acute_and_chronic_pe unweighted logloss: 0.25219429483212547 roc_auc: 0.5699185718759787\n",
      "chronic_pe unweighted logloss: 0.3658677968059921 roc_auc: 0.5523209283713485\n",
      "Tue Oct 20 05:36:53 2020 Fold 1, Epoch 6, lr: 0.0000750, train loss: 0.28514, valid loss: 0.28434, acc: 81.8284, auc: 0.643370\n",
      "Tue Oct 20 05:36:54 2020 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.31007, smth: 0.27296: 100%|██████████| 221/221 [16:58<00:00,  4.61s/it]\n",
      "100%|██████████| 56/56 [04:09<00:00,  4.46s/it]\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5463666134129193 roc_auc: 0.7910527836242831\n",
      "central_pe unweighted logloss: 0.41605952828092413 roc_auc: 0.773259527357888\n",
      "leftsided_pe unweighted logloss: 0.5876606305930806 roc_auc: 0.5898036479617264\n",
      "rightsided_pe unweighted logloss: 0.4121774025702887 roc_auc: 0.6590578322481808\n",
      "acute_and_chronic_pe unweighted logloss: 0.257391052841972 roc_auc: 0.4944409646100846\n",
      "chronic_pe unweighted logloss: 0.3407947517738049 roc_auc: 0.6454081632653061\n",
      "Tue Oct 20 05:58:01 2020 Fold 1, Epoch 7, lr: 0.0000629, train loss: 0.27923, valid loss: 0.28386, acc: 81.3394, auc: 0.658837\n",
      "Tue Oct 20 05:58:02 2020 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.32023, smth: 0.26929: 100%|██████████| 221/221 [17:12<00:00,  4.67s/it]\n",
      "100%|██████████| 56/56 [04:06<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5623903779899512 roc_auc: 0.7872559943873552\n",
      "central_pe unweighted logloss: 0.3956352350960063 roc_auc: 0.7578596267120858\n",
      "leftsided_pe unweighted logloss: 0.575361518891482 roc_auc: 0.6160420611980464\n",
      "rightsided_pe unweighted logloss: 0.41324769804447586 roc_auc: 0.6555342780543854\n",
      "acute_and_chronic_pe unweighted logloss: 0.25419813778007544 roc_auc: 0.5321014719699343\n",
      "chronic_pe unweighted logloss: 0.34801839832763104 roc_auc: 0.6125950380152061\n",
      "Tue Oct 20 06:19:21 2020 Fold 1, Epoch 8, lr: 0.0000500, train loss: 0.27022, valid loss: 0.28454, acc: 81.5651, auc: 0.660231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 20 06:19:22 2020 Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.27920, smth: 0.25858: 100%|██████████| 221/221 [17:13<00:00,  4.67s/it]\n",
      "100%|██████████| 56/56 [04:09<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6613575317434395 roc_auc: 0.7498039701209195\n",
      "central_pe unweighted logloss: 0.4307359688587878 roc_auc: 0.7580015612802498\n",
      "leftsided_pe unweighted logloss: 0.583319540562331 roc_auc: 0.6147961726303199\n",
      "rightsided_pe unweighted logloss: 0.41215141751208506 roc_auc: 0.6466870930677902\n",
      "acute_and_chronic_pe unweighted logloss: 0.25735665355550447 roc_auc: 0.5620106482931413\n",
      "chronic_pe unweighted logloss: 0.34033925530057124 roc_auc: 0.6508103241296519\n",
      "Tue Oct 20 06:40:44 2020 Fold 1, Epoch 9, lr: 0.0000371, train loss: 0.26221, valid loss: 0.31302, acc: 81.0384, auc: 0.663685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 20 06:40:44 2020 Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.29771, smth: 0.24964: 100%|██████████| 221/221 [16:59<00:00,  4.61s/it]\n",
      "100%|██████████| 56/56 [04:12<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5834349097135323 roc_auc: 0.786863934629194\n",
      "central_pe unweighted logloss: 0.4110152552589673 roc_auc: 0.7762046696472926\n",
      "leftsided_pe unweighted logloss: 0.5759931126163755 roc_auc: 0.6168394298813914\n",
      "rightsided_pe unweighted logloss: 0.4143260713124282 roc_auc: 0.641899655304481\n",
      "acute_and_chronic_pe unweighted logloss: 0.2571756249907559 roc_auc: 0.5461165048543689\n",
      "chronic_pe unweighted logloss: 0.34281401947964796 roc_auc: 0.6510104041616647\n",
      "Tue Oct 20 07:01:56 2020 Fold 1, Epoch 10, lr: 0.0000250, train loss: 0.25157, valid loss: 0.29164, acc: 81.9037, auc: 0.669822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 20 07:01:56 2020 Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.33258, smth: 0.23658: 100%|██████████| 221/221 [16:58<00:00,  4.61s/it]\n",
      "100%|██████████| 56/56 [04:11<00:00,  4.50s/it]\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5781384986214567 roc_auc: 0.7892781973505015\n",
      "central_pe unweighted logloss: 0.40820808295353944 roc_auc: 0.7758498332268824\n",
      "leftsided_pe unweighted logloss: 0.5738826338895523 roc_auc: 0.6251619655138044\n",
      "rightsided_pe unweighted logloss: 0.4067400898963095 roc_auc: 0.6751819226350058\n",
      "acute_and_chronic_pe unweighted logloss: 0.2575055295370233 roc_auc: 0.5050109614782337\n",
      "chronic_pe unweighted logloss: 0.337097610702263 roc_auc: 0.6710684273709484\n",
      "Tue Oct 20 07:23:07 2020 Fold 1, Epoch 11, lr: 0.0000146, train loss: 0.23867, valid loss: 0.28909, acc: 82.0918, auc: 0.673592\n",
      "Tue Oct 20 07:23:07 2020 Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.25364, smth: 0.23115: 100%|██████████| 221/221 [17:06<00:00,  4.64s/it]\n",
      "100%|██████████| 56/56 [04:11<00:00,  4.49s/it]\n",
      "  0%|          | 0/221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5771396220346353 roc_auc: 0.7898559696256862\n",
      "central_pe unweighted logloss: 0.4123681690380961 roc_auc: 0.7746788730395288\n",
      "leftsided_pe unweighted logloss: 0.5750730121140337 roc_auc: 0.6234426392903418\n",
      "rightsided_pe unweighted logloss: 0.4094925764107206 roc_auc: 0.6582152432018383\n",
      "acute_and_chronic_pe unweighted logloss: 0.25739944486145105 roc_auc: 0.530300657688694\n",
      "chronic_pe unweighted logloss: 0.3365358260815488 roc_auc: 0.6729191676670668\n",
      "Tue Oct 20 07:44:25 2020 Fold 1, Epoch 12, lr: 0.0000067, train loss: 0.23189, valid loss: 0.28958, acc: 82.1294, auc: 0.674902\n",
      "Tue Oct 20 07:44:25 2020 Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.27777, smth: 0.22572: 100%|██████████| 221/221 [17:00<00:00,  4.62s/it]\n",
      "100%|██████████| 56/56 [04:11<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5624111860824442 roc_auc: 0.7925797532086996\n",
      "central_pe unweighted logloss: 0.41566016367120506 roc_auc: 0.7779433681073025\n",
      "leftsided_pe unweighted logloss: 0.5728705471652743 roc_auc: 0.6210754510116615\n",
      "rightsided_pe unweighted logloss: 0.40736782486901596 roc_auc: 0.669207200306396\n",
      "acute_and_chronic_pe unweighted logloss: 0.2561467587800684 roc_auc: 0.524036955840902\n",
      "chronic_pe unweighted logloss: 0.3326119419616178 roc_auc: 0.6803221288515406\n",
      "Tue Oct 20 08:05:36 2020 Fold 1, Epoch 13, lr: 0.0000017, train loss: 0.22907, valid loss: 0.28594, acc: 82.3175, auc: 0.677527\n"
     ]
    }
   ],
   "source": [
    "run(fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1769 442\n",
      "Tue Oct 20 08:05:38 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.40598, smth: 0.37060: 100%|██████████| 222/222 [17:07<00:00,  4.63s/it]\n",
      "100%|██████████| 56/56 [04:06<00:00,  4.40s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6598670919556423 roc_auc: 0.6635249366018596\n",
      "central_pe unweighted logloss: 0.5414252523922812 roc_auc: 0.6646894051738342\n",
      "leftsided_pe unweighted logloss: 0.6265587385962991 roc_auc: 0.4711098398169336\n",
      "rightsided_pe unweighted logloss: 0.4950333655352506 roc_auc: 0.49768654524089306\n",
      "acute_and_chronic_pe unweighted logloss: 0.3887430720739235 roc_auc: 0.5257026627218935\n",
      "chronic_pe unweighted logloss: 0.5221017897129059 roc_auc: 0.5665312630499981\n",
      "Tue Oct 20 08:26:52 2020 Fold 2, Epoch 1, lr: 0.0000100, train loss: 0.38948, valid loss: 0.35921, acc: 79.0724, auc: 0.564874\n",
      "Tue Oct 20 08:26:52 2020 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.24248, smth: 0.31755: 100%|██████████| 222/222 [17:14<00:00,  4.66s/it]\n",
      "100%|██████████| 56/56 [04:04<00:00,  4.36s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:942: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6639675889754187 roc_auc: 0.6113482671174979\n",
      "central_pe unweighted logloss: 0.48998648915819115 roc_auc: 0.6933926511781183\n",
      "leftsided_pe unweighted logloss: 0.6190651742176773 roc_auc: 0.5619755911517925\n",
      "rightsided_pe unweighted logloss: 0.45137569867917315 roc_auc: 0.5519976498237368\n",
      "acute_and_chronic_pe unweighted logloss: 0.22395038855898433 roc_auc: 0.5245931952662721\n",
      "chronic_pe unweighted logloss: 0.44568727556531784 roc_auc: 0.5820583880642346\n",
      "Tue Oct 20 08:48:11 2020 Fold 2, Epoch 2, lr: 0.0001000, train loss: 0.32548, valid loss: 0.33133, acc: 79.0724, auc: 0.587561\n",
      "Tue Oct 20 08:48:11 2020 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.26563, smth: 0.31177: 100%|██████████| 222/222 [17:06<00:00,  4.62s/it]\n",
      "100%|██████████| 56/56 [04:08<00:00,  4.44s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.7381557443124407 roc_auc: 0.6468934911242603\n",
      "central_pe unweighted logloss: 0.46128184148595075 roc_auc: 0.6966880869995057\n",
      "leftsided_pe unweighted logloss: 0.6144073692517044 roc_auc: 0.5687690694126621\n",
      "rightsided_pe unweighted logloss: 0.4411599636667859 roc_auc: 0.6246327849588719\n",
      "acute_and_chronic_pe unweighted logloss: 0.22155872256204284 roc_auc: 0.5817307692307692\n",
      "chronic_pe unweighted logloss: 0.43115416157367004 roc_auc: 0.5720359895220378\n",
      "Tue Oct 20 09:09:26 2020 Fold 2, Epoch 3, lr: 0.0001000, train loss: 0.31105, valid loss: 0.34281, acc: 78.6953, auc: 0.615125\n",
      "Tue Oct 20 09:09:26 2020 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.27885, smth: 0.29041: 100%|██████████| 222/222 [17:05<00:00,  4.62s/it]\n",
      "100%|██████████| 56/56 [04:04<00:00,  4.36s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6177645425114157 roc_auc: 0.6909129332206255\n",
      "central_pe unweighted logloss: 0.5046044145795049 roc_auc: 0.7252924699291482\n",
      "leftsided_pe unweighted logloss: 0.6195908463918246 roc_auc: 0.5683638443935928\n",
      "rightsided_pe unweighted logloss: 0.44651634622854075 roc_auc: 0.581081081081081\n",
      "acute_and_chronic_pe unweighted logloss: 0.2228533264704689 roc_auc: 0.5880177514792899\n",
      "chronic_pe unweighted logloss: 0.43563043474476804 roc_auc: 0.5771231160548195\n",
      "Tue Oct 20 09:30:36 2020 Fold 2, Epoch 4, lr: 0.0000933, train loss: 0.29794, valid loss: 0.32136, acc: 79.9020, auc: 0.621799\n",
      "Tue Oct 20 09:30:36 2020 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.25841, smth: 0.29024: 100%|██████████| 222/222 [17:05<00:00,  4.62s/it]\n",
      "100%|██████████| 56/56 [04:07<00:00,  4.41s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.606521496852666 roc_auc: 0.7579036348267119\n",
      "central_pe unweighted logloss: 0.48598361511796934 roc_auc: 0.7512605042016807\n",
      "leftsided_pe unweighted logloss: 0.6217073633154323 roc_auc: 0.5937261632341724\n",
      "rightsided_pe unweighted logloss: 0.4417703729712855 roc_auc: 0.5917670387779083\n",
      "acute_and_chronic_pe unweighted logloss: 0.22444389054627575 roc_auc: 0.5593565088757396\n",
      "chronic_pe unweighted logloss: 0.43442563666241474 roc_auc: 0.5680877719145059\n",
      "Tue Oct 20 09:51:48 2020 Fold 2, Epoch 5, lr: 0.0000854, train loss: 0.28784, valid loss: 0.31594, acc: 80.1659, auc: 0.637017\n",
      "Tue Oct 20 09:51:48 2020 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.16565, smth: 0.27648: 100%|██████████| 222/222 [17:28<00:00,  4.72s/it]\n",
      "100%|██████████| 56/56 [04:05<00:00,  4.39s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5767444948122175 roc_auc: 0.7482248520710059\n",
      "central_pe unweighted logloss: 0.43742810354496425 roc_auc: 0.7307628933926512\n",
      "leftsided_pe unweighted logloss: 0.6114292024167011 roc_auc: 0.5872663996948895\n",
      "rightsided_pe unweighted logloss: 0.4362023583807186 roc_auc: 0.6268727967097532\n",
      "acute_and_chronic_pe unweighted logloss: 0.22334091852490717 roc_auc: 0.5673076923076923\n",
      "chronic_pe unweighted logloss: 0.441019186640487 roc_auc: 0.5861204965642914\n",
      "Tue Oct 20 10:13:23 2020 Fold 2, Epoch 6, lr: 0.0000750, train loss: 0.27898, valid loss: 0.30163, acc: 80.4676, auc: 0.641093\n",
      "Tue Oct 20 10:13:23 2020 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.42058, smth: 0.27390: 100%|██████████| 222/222 [17:27<00:00,  4.72s/it]\n",
      "100%|██████████| 56/56 [04:09<00:00,  4.46s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5666598430294776 roc_auc: 0.7772612003381235\n",
      "central_pe unweighted logloss: 0.4140056433894659 roc_auc: 0.7737683308617564\n",
      "leftsided_pe unweighted logloss: 0.5895312601064092 roc_auc: 0.6614702517162472\n",
      "rightsided_pe unweighted logloss: 0.4334394155571667 roc_auc: 0.6314262632197414\n",
      "acute_and_chronic_pe unweighted logloss: 0.22353384841857182 roc_auc: 0.5568602071005917\n",
      "chronic_pe unweighted logloss: 0.427286132782428 roc_auc: 0.5828556243119092\n",
      "Tue Oct 20 10:35:00 2020 Fold 2, Epoch 7, lr: 0.0000629, train loss: 0.27450, valid loss: 0.29366, acc: 80.4299, auc: 0.663940\n",
      "Tue Oct 20 10:35:00 2020 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.34419, smth: 0.26595:  65%|██████▍   | 144/222 [11:14<02:26,  1.88s/it]"
     ]
    }
   ],
   "source": [
    "run(fold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1769 442\n",
      "Tue Oct 20 12:29:00 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.44106, smth: 0.37531: 100%|██████████| 222/222 [16:52<00:00,  4.56s/it]\n",
      "100%|██████████| 56/56 [04:16<00:00,  4.57s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6736876961872049 roc_auc: 0.5792815371762741\n",
      "central_pe unweighted logloss: 0.5310533021774767 roc_auc: 0.6654686741136474\n",
      "leftsided_pe unweighted logloss: 0.6334402894946785 roc_auc: 0.5587737168945288\n",
      "rightsided_pe unweighted logloss: 0.4996128991853058 roc_auc: 0.4745062604879308\n",
      "acute_and_chronic_pe unweighted logloss: 0.43546410066779384 roc_auc: 0.554126213592233\n",
      "chronic_pe unweighted logloss: 0.4950026358010003 roc_auc: 0.5686757215619694\n",
      "Tue Oct 20 12:50:08 2020 Fold 3, Epoch 1, lr: 0.0000100, train loss: 0.39852, valid loss: 0.36311, acc: 79.0724, auc: 0.566805\n",
      "Tue Oct 20 12:50:08 2020 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.21136, smth: 0.32182: 100%|██████████| 222/222 [17:10<00:00,  4.64s/it]\n",
      "100%|██████████| 56/56 [04:14<00:00,  4.55s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:942: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.7341759153072853 roc_auc: 0.5842522974101921\n",
      "central_pe unweighted logloss: 0.4825761432578256 roc_auc: 0.6532621013436943\n",
      "leftsided_pe unweighted logloss: 0.6054844700845119 roc_auc: 0.5596573476350606\n",
      "rightsided_pe unweighted logloss: 0.3975256281774238 roc_auc: 0.5995008820618734\n",
      "acute_and_chronic_pe unweighted logloss: 0.24695068637406395 roc_auc: 0.5953074433656957\n",
      "chronic_pe unweighted logloss: 0.39881931263869164 roc_auc: 0.6213921901528014\n",
      "Tue Oct 20 13:11:33 2020 Fold 3, Epoch 2, lr: 0.0001000, train loss: 0.32756, valid loss: 0.34186, acc: 78.5068, auc: 0.602229\n",
      "Tue Oct 20 13:11:33 2020 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.20957, smth: 0.30987: 100%|██████████| 222/222 [16:44<00:00,  4.52s/it]\n",
      "100%|██████████| 56/56 [04:12<00:00,  4.51s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6162131369552192 roc_auc: 0.7034461152882205\n",
      "central_pe unweighted logloss: 0.4269968878848655 roc_auc: 0.7581026388214344\n",
      "leftsided_pe unweighted logloss: 0.5882289803742823 roc_auc: 0.6247514788542256\n",
      "rightsided_pe unweighted logloss: 0.393655312302358 roc_auc: 0.5835807409319738\n",
      "acute_and_chronic_pe unweighted logloss: 0.24867817455253718 roc_auc: 0.4935275080906149\n",
      "chronic_pe unweighted logloss: 0.4020824412650922 roc_auc: 0.5922750424448218\n",
      "Tue Oct 20 13:32:30 2020 Fold 3, Epoch 3, lr: 0.0001000, train loss: 0.31441, valid loss: 0.30532, acc: 80.7692, auc: 0.625947\n",
      "Tue Oct 20 13:32:31 2020 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.43399, smth: 0.29685: 100%|██████████| 222/222 [16:46<00:00,  4.53s/it]\n",
      "100%|██████████| 56/56 [04:15<00:00,  4.56s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.583208897151053 roc_auc: 0.7474728487886383\n",
      "central_pe unweighted logloss: 0.4208670635433758 roc_auc: 0.7755868544600938\n",
      "leftsided_pe unweighted logloss: 0.5833261034523065 roc_auc: 0.6480695122849218\n",
      "rightsided_pe unweighted logloss: 0.395468013382167 roc_auc: 0.5994148272449551\n",
      "acute_and_chronic_pe unweighted logloss: 0.251465056774236 roc_auc: 0.4832524271844659\n",
      "chronic_pe unweighted logloss: 0.4037083994883757 roc_auc: 0.6133276740237692\n",
      "Tue Oct 20 13:53:32 2020 Fold 3, Epoch 4, lr: 0.0000933, train loss: 0.30127, valid loss: 0.29681, acc: 80.9955, auc: 0.644521\n",
      "Tue Oct 20 13:53:32 2020 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.51320, smth: 0.29123: 100%|██████████| 222/222 [16:52<00:00,  4.56s/it]\n",
      "100%|██████████| 56/56 [04:12<00:00,  4.50s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6056706260708561 roc_auc: 0.743421052631579\n",
      "central_pe unweighted logloss: 0.4129340590664704 roc_auc: 0.7905131941071718\n",
      "leftsided_pe unweighted logloss: 0.5802673796419374 roc_auc: 0.6347168699835547\n",
      "rightsided_pe unweighted logloss: 0.39195811903163186 roc_auc: 0.6103007615851297\n",
      "acute_and_chronic_pe unweighted logloss: 0.24934754692591155 roc_auc: 0.5296925566343043\n",
      "chronic_pe unweighted logloss: 0.3993187426880204 roc_auc: 0.5894312393887946\n",
      "Tue Oct 20 14:14:37 2020 Fold 3, Epoch 5, lr: 0.0000854, train loss: 0.28809, valid loss: 0.30019, acc: 81.4103, auc: 0.649679\n",
      "Tue Oct 20 14:14:37 2020 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.39894, smth: 0.27591: 100%|██████████| 222/222 [17:03<00:00,  4.61s/it]\n",
      "100%|██████████| 56/56 [04:14<00:00,  4.55s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.7304691404432935 roc_auc: 0.7053258145363408\n",
      "central_pe unweighted logloss: 0.4482644090768186 roc_auc: 0.785170794884248\n",
      "leftsided_pe unweighted logloss: 0.6297748871821893 roc_auc: 0.5862153604477063\n",
      "rightsided_pe unweighted logloss: 0.39697099741278596 roc_auc: 0.5771266296630955\n",
      "acute_and_chronic_pe unweighted logloss: 0.25301982387394656 roc_auc: 0.5619741100323625\n",
      "chronic_pe unweighted logloss: 0.39530086282185567 roc_auc: 0.6223259762308998\n",
      "Tue Oct 20 14:35:55 2020 Fold 3, Epoch 6, lr: 0.0000750, train loss: 0.27953, valid loss: 0.33742, acc: 79.7511, auc: 0.639690\n",
      "Tue Oct 20 14:35:55 2020 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.20251, smth: 0.27305: 100%|██████████| 222/222 [16:44<00:00,  4.53s/it]\n",
      "100%|██████████| 56/56 [04:12<00:00,  4.50s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5650707726868299 roc_auc: 0.7723475355054303\n",
      "central_pe unweighted logloss: 0.4198736541280818 roc_auc: 0.781771086287842\n",
      "leftsided_pe unweighted logloss: 0.606407246236348 roc_auc: 0.6034707051864215\n",
      "rightsided_pe unweighted logloss: 0.38676421632105273 roc_auc: 0.6272965879265092\n",
      "acute_and_chronic_pe unweighted logloss: 0.2474131795000369 roc_auc: 0.5574433656957929\n",
      "chronic_pe unweighted logloss: 0.3872536422592078 roc_auc: 0.6353140916808149\n",
      "Tue Oct 20 14:56:52 2020 Fold 3, Epoch 7, lr: 0.0000629, train loss: 0.27635, valid loss: 0.29142, acc: 80.8446, auc: 0.662941\n",
      "Tue Oct 20 14:56:52 2020 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.49152, smth: 0.26989: 100%|██████████| 222/222 [16:55<00:00,  4.58s/it]\n",
      "100%|██████████| 56/56 [04:13<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.545069342582356 roc_auc: 0.7860484544695072\n",
      "central_pe unweighted logloss: 0.3906641082387266 roc_auc: 0.8272948033025741\n",
      "leftsided_pe unweighted logloss: 0.5691186018136427 roc_auc: 0.6591639871382636\n",
      "rightsided_pe unweighted logloss: 0.37827511451721224 roc_auc: 0.6515210188890325\n",
      "acute_and_chronic_pe unweighted logloss: 0.24807598231132752 roc_auc: 0.542799352750809\n",
      "chronic_pe unweighted logloss: 0.38609749677999794 roc_auc: 0.6671052631578948\n",
      "Tue Oct 20 15:18:02 2020 Fold 3, Epoch 8, lr: 0.0000500, train loss: 0.26662, valid loss: 0.28029, acc: 81.8250, auc: 0.688989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 20 15:18:02 2020 Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.68049, smth: 0.25919: 100%|██████████| 222/222 [17:04<00:00,  4.62s/it]\n",
      "100%|██████████| 56/56 [04:14<00:00,  4.54s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5795482734420518 roc_auc: 0.7806599832915622\n",
      "central_pe unweighted logloss: 0.4017807419687863 roc_auc: 0.8304678646592197\n",
      "leftsided_pe unweighted logloss: 0.5911337427322951 roc_auc: 0.6359686801993079\n",
      "rightsided_pe unweighted logloss: 0.38156922192552983 roc_auc: 0.6568564175379716\n",
      "acute_and_chronic_pe unweighted logloss: 0.24849803398923773 roc_auc: 0.5425566343042071\n",
      "chronic_pe unweighted logloss: 0.38891231442687874 roc_auc: 0.621434634974533\n",
      "Tue Oct 20 15:39:21 2020 Fold 3, Epoch 9, lr: 0.0000371, train loss: 0.25936, valid loss: 0.29152, acc: 81.3348, auc: 0.677991\n",
      "Tue Oct 20 15:39:22 2020 Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.22799, smth: 0.23951:  26%|██▌       | 57/222 [04:54<14:12,  5.17s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-d60fffb0cf13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-203-b6c4b632f717>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mscheduler_warmup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-db1efee9c301>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run(fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1769 442\n",
      "Tue Oct 20 15:49:03 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.33367, smth: 0.37621: 100%|██████████| 222/222 [17:20<00:00,  4.69s/it]\n",
      "100%|██████████| 56/56 [04:19<00:00,  4.64s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6629508653512368 roc_auc: 0.6284597574186971\n",
      "central_pe unweighted logloss: 0.4810492088891802 roc_auc: 0.6388794567062818\n",
      "leftsided_pe unweighted logloss: 0.6495623357290596 roc_auc: 0.5214284098875999\n",
      "rightsided_pe unweighted logloss: 0.5054865071541583 roc_auc: 0.4790540540540541\n",
      "acute_and_chronic_pe unweighted logloss: 0.4150394346918995 roc_auc: 0.4820906737914336\n",
      "chronic_pe unweighted logloss: 0.49935450495907624 roc_auc: 0.6102716468590831\n",
      "Tue Oct 20 16:10:43 2020 Fold 4, Epoch 1, lr: 0.0000100, train loss: 0.39941, valid loss: 0.35321, acc: 79.5249, auc: 0.560031\n",
      "Tue Oct 20 16:10:43 2020 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.32610, smth: 0.32582: 100%|██████████| 222/222 [17:18<00:00,  4.68s/it]\n",
      "100%|██████████| 56/56 [04:20<00:00,  4.65s/it]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:942: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6498487372945876 roc_auc: 0.6519956666737472\n",
      "central_pe unweighted logloss: 0.4153146476345769 roc_auc: 0.7199066213921902\n",
      "leftsided_pe unweighted logloss: 0.6398492042160682 roc_auc: 0.616878123798539\n",
      "rightsided_pe unweighted logloss: 0.4359622176955728 roc_auc: 0.621509009009009\n",
      "acute_and_chronic_pe unweighted logloss: 0.24438470084961858 roc_auc: 0.5066377223010771\n",
      "chronic_pe unweighted logloss: 0.3928904267390389 roc_auc: 0.6862054329371816\n",
      "Tue Oct 20 16:32:23 2020 Fold 4, Epoch 2, lr: 0.0001000, train loss: 0.33003, valid loss: 0.31503, acc: 79.6757, auc: 0.633857\n",
      "Tue Oct 20 16:32:23 2020 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.37255, smth: 0.31443: 100%|██████████| 222/222 [17:13<00:00,  4.66s/it]\n",
      "100%|██████████| 56/56 [04:20<00:00,  4.65s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.6758954719855235 roc_auc: 0.6164156594515369\n",
      "central_pe unweighted logloss: 0.38618651140540233 roc_auc: 0.7062818336162988\n",
      "leftsided_pe unweighted logloss: 0.6455229380551506 roc_auc: 0.5188049845082208\n",
      "rightsided_pe unweighted logloss: 0.43531439328625193 roc_auc: 0.619557057057057\n",
      "acute_and_chronic_pe unweighted logloss: 0.24158288508957057 roc_auc: 0.5568172330299741\n",
      "chronic_pe unweighted logloss: 0.3936889992681294 roc_auc: 0.6849745331069609\n",
      "Tue Oct 20 16:53:57 2020 Fold 4, Epoch 3, lr: 0.0001000, train loss: 0.31373, valid loss: 0.31715, acc: 79.4872, auc: 0.617142\n",
      "Tue Oct 20 16:53:57 2020 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.42567, smth: 0.30240: 100%|██████████| 222/222 [17:20<00:00,  4.69s/it]\n",
      "100%|██████████| 56/56 [04:20<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.5789520390652019 roc_auc: 0.7203305223357479\n",
      "central_pe unweighted logloss: 0.3577630628528267 roc_auc: 0.7537351443123939\n",
      "leftsided_pe unweighted logloss: 0.6725581294574619 roc_auc: 0.5830562905669765\n",
      "rightsided_pe unweighted logloss: 0.4315416471994739 roc_auc: 0.6251126126126125\n",
      "acute_and_chronic_pe unweighted logloss: 0.24311487594138984 roc_auc: 0.5377807464306588\n",
      "chronic_pe unweighted logloss: 0.3951063868484346 roc_auc: 0.6586587436332767\n",
      "Tue Oct 20 17:15:38 2020 Fold 4, Epoch 4, lr: 0.0000933, train loss: 0.30123, valid loss: 0.29142, acc: 81.2217, auc: 0.646446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 20 17:15:38 2020 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.52351, smth: 0.29145: 100%|██████████| 222/222 [17:05<00:00,  4.62s/it]\n",
      "100%|██████████| 56/56 [04:10<00:00,  4.48s/it]\n",
      "  0%|          | 0/222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rv_lv_ratio_gte_1 unweighted logloss: 0.658320599094421 roc_auc: 0.728466129957304\n",
      "central_pe unweighted logloss: 0.4810366543911701 roc_auc: 0.7625212224108657\n",
      "leftsided_pe unweighted logloss: 0.7045225577209803 roc_auc: 0.5956532555352014\n",
      "rightsided_pe unweighted logloss: 0.42534642360211095 roc_auc: 0.6576576576576576\n",
      "acute_and_chronic_pe unweighted logloss: 0.2435959867745368 roc_auc: 0.5105619103281289\n",
      "chronic_pe unweighted logloss: 0.38501803730340567 roc_auc: 0.6635823429541597\n",
      "Tue Oct 20 17:36:55 2020 Fold 4, Epoch 5, lr: 0.0000854, train loss: 0.29327, valid loss: 0.32829, acc: 78.0920, auc: 0.653074\n",
      "Tue Oct 20 17:36:55 2020 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.28603, smth: 0.27965: 100%|██████████| 222/222 [16:32<00:00,  4.47s/it]\n",
      " 57%|█████▋    | 32/56 [02:23<00:34,  1.43s/it]"
     ]
    }
   ],
   "source": [
    "run(fold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu101.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1602315363639",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect postproces for pe_present_on_image -> pe_exam\n",
    "\n",
    "tested by exp010, fold0 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/haito/kaggle/rsna-str/workdir\n"
    }
   ],
   "source": [
    "%cd ~/kaggle/rsna-str/workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.factory import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATADIR = Path(\"../input/rsna-str-pulmonary-embolism-detection/\")\n",
    "\n",
    "train = pd.read_csv(DATADIR / \"train.csv\")\n",
    "pre = pd.read_csv(DATADIR / \"split.csv\")\n",
    "train = train.merge(pre, on=\"StudyInstanceUID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train[train.fold == FOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = t.StudyInstanceUID.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = t.groupby(\"StudyInstanceUID\")[\"SOPInstanceUID\"].apply(list)\n",
    "agg_one = t.groupby(\"StudyInstanceUID\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post1(p_arr, q=90):\n",
    "    return np.percentile(p_arr, q=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### exp 010\n",
    "p = \"output/010_pe_pos/out.valid.fold0\"  # ep0\n",
    "# p = \"output/010_pe_pos/out.valid.fold0_ep1\"\n",
    "\n",
    "res = load_pickle(p)\n",
    "\n",
    "raw_pred = pd.DataFrame({\n",
    "    \"sop\": res[\"ids\"],\n",
    "    \"pe_present_on_image\": res[\"outputs\"][\"pe_present_on_image\"],\n",
    "    \"rightsided_pe\": res[\"outputs\"][\"rightsided_pe\"],\n",
    "    \"leftsided_pe\": res[\"outputs\"][\"leftsided_pe\"],\n",
    "    \"central_pe\": res[\"outputs\"][\"central_pe\"],\n",
    "})\n",
    "raw_pred = raw_pred.set_index(\"sop\")\n",
    "\n",
    "### \n",
    "def get_pred(_path):\n",
    "    res = load_pickle(_path)\n",
    "    raw_pred = pd.DataFrame({\n",
    "        \"sop\": res[\"ids\"],\n",
    "        \"pe_present\": res[\"outputs\"][\"pe_present_on_image\"]  # 010 or later\n",
    "    })\n",
    "    return raw_pred.set_index(\"sop\")\n",
    "\n",
    "raw_pred_010ep0 = get_pred(\"output/010_pe_pos/out.valid.fold0\")\n",
    "raw_pred_010ep1 = get_pred(\"output/010_pe_pos/out.valid.fold0_ep1\")\n",
    "raw_pred_031tune_ep2 = get_pred(\"output/031_pe_present___oversample___tune/valid.fold0-ep2.pickle\")\n",
    "raw_pred_035ep1       = get_pred(\"output/035_pe_present___448/valid.fold0-ep1.picle\")\n",
    "raw_pred_fold1_035ep1 = get_pred(\"output/035_pe_present___448___apex___resume/valid.fold1-ep1.pickle\")\n",
    "raw_pred_fold1_035ep2 = get_pred(\"output/035_pe_present___448___apex___resume/valid.fold1-ep2.pickle\")\n",
    "\n",
    "\n",
    "raw_pred_036ep3 = get_pred(\"output/036_pe_present___448___cutmix/valid.fold0-ep3.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 001\n",
    "_path = \"output/001_base/fold0_valid.pickle\"\n",
    "res = load_pickle(_path)\n",
    "raw_pred = pd.DataFrame({\n",
    "    \"sop\": res[\"ids\"],\n",
    "    \"pe_present\": res[\"outputs\"]\n",
    "})\n",
    "raw_pred = raw_pred.set_index(\"sop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" exp 001 model (ep1)\n",
    "q=90.00 logloss:0.4335881782152035\n",
    "q=91.00 logloss:0.4261582133852183\n",
    "q=92.00 logloss:0.41820680933855464\n",
    "q=93.00 logloss:0.40965706920377787\n",
    "q=94.00 logloss:0.40250102547323763\n",
    "q=95.00 logloss:0.399617003382453   <=== たまたま Best\n",
    "q=96.00 logloss:0.4014378415196566\n",
    "q=97.00 logloss:0.40659142078878496\n",
    "q=98.00 logloss:0.4293089602081556\n",
    "q=99.00 logloss:0.4881203309768597\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" exp 010 model (ep0)\n",
    "q=90 logloss:0.580963053992852\n",
    "q=91 logloss:0.5561516892147172\n",
    "q=92 logloss:0.5302883445027334\n",
    "q=93 logloss:0.5057102176781858\n",
    "q=94 logloss:0.48133613115138896\n",
    "q=95 logloss:0.4547570238934727   <=========== Bad\n",
    "q=96 logloss:0.4293633715604374\n",
    "q=97 logloss:0.40440298977917516\n",
    "q=98 logloss:0.383646086091538\n",
    "q=98.80 logloss:0.37546814335089845\n",
    "q=98.90 logloss:0.3744332339894111   <=========== Mininum for fold0\n",
    "q=99.00 logloss:0.3745150839621268\n",
    "q=99 logloss:0.374515083962127\n",
    "q=99.10 logloss:0.3755236864711825\n",
    "q=99.20 logloss:0.3776048971290255\n",
    "q=99.5 logloss:0.389937762524077\n",
    "q=99.7 logloss:0.40671684673171016\n",
    "q=99.9 logloss:0.43696034136869655\n",
    "q=99.95 logloss:0.44722869414163663\n",
    "q=99.99 logloss:0.4569151069554547\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" exp 010 model (ep1)\n",
    "q=90.00 logloss:0.5279595949554328\n",
    "q=91.00 logloss:0.5052608242921037\n",
    "q=92.00 logloss:0.4834110695747726\n",
    "q=93.00 logloss:0.46385352130528656\n",
    "q=94.00 logloss:0.4473139354706962\n",
    "q=95.00 logloss:0.43102377556895444\n",
    "q=96.00 logloss:0.41591824329556415\n",
    "q=97.00 logloss:0.40408809195191403   <================ Best. epが進むほど最適なpercentilがさがる. epが進むとOver-confになるからだと思われる. exp001,best 0.3996\n",
    "q=98.00 logloss:0.4081253578858078\n",
    "q=99.00 logloss:0.4430865048629079\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 3.8250639579850194  # for exp001ep1\n",
    "def calib_p(arr, factor=F):  # set factor>1 to enhance positive prob\n",
    "    return arr * factor / (arr * factor + (1-arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calib後の po_exam推定\n",
    "\n",
    "calibなし, best\n",
    "q=95.00 logloss:0.399617003382453\n",
    "\n",
    "\n",
    "q=60.00 logloss:0.698643776447078\n",
    "q=63.00 logloss:0.6365354999541909\n",
    "q=66.00 logloss:0.5879396129561644\n",
    "q=69.00 logloss:0.5459351137856083\n",
    "q=72.00 logloss:0.51321447134653\n",
    "q=75.00 logloss:0.4869159619202598\n",
    "q=78.00 logloss:0.46734739184806373\n",
    "q=81.00 logloss:0.45602309782309475\n",
    "q=84.00 logloss:0.4533383621932218   <=== Bad\n",
    "q=87.00 logloss:0.46169121075914676\n",
    "q=90.00 logloss:0.4797557469032024\n",
    "q=93.00 logloss:0.5235644453652069\n",
    "q=96.00 logloss:0.6101237719455836\n",
    "q=99.00 logloss:0.8752916874879507\n",
    "\n",
    "そもそもN-percentileがよくなさそうではある\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 後処理 : pe_preesnt -> pos_exam or not\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "post2_prob_pos : \n",
    "ナイーブな後処理\n",
    "いくつかパターンためしたがどれもだめ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"None of [Index(['c0f3cb036d06', 'f57ffd3883b6', '41220fda34a3', '13b685b4b14f',\\n       'be0b7524ffb4', 'c7b99cb454d4', 'e153deb813ed', 'c6bbe08f2736',\\n       '09886998dc28', '5b5226ac7bac',\\n       ...\\n       '11449e662c07', '0de5072ee990', '726aec3373a4', '7b0018a6d3b2',\\n       'd2253e773f05', '1fa18364e089', 'ee19a5f9a850', 'c9dfdd668a12',\\n       '622e6f6ec380', '947f931d8855'],\\n      dtype='object', name='sop', length=124)] are in the [index]\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a79398903979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mLABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_is_pe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mraw_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msops\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# preds for current study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pe pre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['c0f3cb036d06', 'f57ffd3883b6', '41220fda34a3', '13b685b4b14f',\\n       'be0b7524ffb4', 'c7b99cb454d4', 'e153deb813ed', 'c6bbe08f2736',\\n       '09886998dc28', '5b5226ac7bac',\\n       ...\\n       '11449e662c07', '0de5072ee990', '726aec3373a4', '7b0018a6d3b2',\\n       'd2253e773f05', '1fa18364e089', 'ee19a5f9a850', 'c9dfdd668a12',\\n       '622e6f6ec380', '947f931d8855'],\\n      dtype='object', name='sop', length=124)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "def post2_prob_pos(p_pe_arr, q=1.0):\n",
    "    p_pe_arr = np.sort(p_pe_arr.values)[int(len(p_pe_arr)*0.7):]\n",
    "    length = len(p_pe_arr)\n",
    "    \"\"\"q : [0,1] \"\"\"\n",
    "    neg_prob = 1.0\n",
    "    for p in p_pe_arr:\n",
    "        neg_prob *= np.power((1-p), 60 / length)\n",
    "    return 1 - neg_prob\n",
    "\n",
    "# for factor in [0.01, 0.02, 0.05, 0.1, 0.2, 0.4, 1.0]:\n",
    "# for factor in [0.05]:\n",
    "for _ in [0.05]:\n",
    "\n",
    "    LABELS = []\n",
    "    PREDS = []\n",
    "\n",
    "    for study in t.StudyInstanceUID.unique():\n",
    "        sops = agg.loc[study]\n",
    "        label = agg_one.loc[study]\n",
    "        label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "        LABELS.append(label_is_pe)\n",
    "\n",
    "        prediction =  raw_pred.loc[sops]  # preds for current study\n",
    "\n",
    "        # pe pre\n",
    "        probs_pe_present = prediction.pe_present\n",
    "        probs_pe_present = calib_p(probs_pe_present)\n",
    "        pe_prob = post2_prob_pos(probs_pe_present, q=0.2)\n",
    "\n",
    "\n",
    "        pe_prob = calib_p(pe_prob, factor=0.02)\n",
    "\n",
    "        PREDS.append(pe_prob)\n",
    "\n",
    "        # break\n",
    "    # break\n",
    "    print( \"mean\", np.mean(PREDS) )\n",
    "\n",
    "    plt.hist(PREDS, bins=50)\n",
    "    plt.show()\n",
    "    print(f\"factor={factor:.3f} logloss:{log_loss(LABELS, PREDS)}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"None of [Index(['c0f3cb036d06', 'f57ffd3883b6', '41220fda34a3', '13b685b4b14f',\\n       'be0b7524ffb4', 'c7b99cb454d4', 'e153deb813ed', 'c6bbe08f2736',\\n       '09886998dc28', '5b5226ac7bac',\\n       ...\\n       '11449e662c07', '0de5072ee990', '726aec3373a4', '7b0018a6d3b2',\\n       'd2253e773f05', '1fa18364e089', 'ee19a5f9a850', 'c9dfdd668a12',\\n       '622e6f6ec380', '947f931d8855'],\\n      dtype='object', name='sop', length=124)] are in the [index]\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ab1718901b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mLABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_is_pe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mraw_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msops\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# preds for current study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# pe pre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['c0f3cb036d06', 'f57ffd3883b6', '41220fda34a3', '13b685b4b14f',\\n       'be0b7524ffb4', 'c7b99cb454d4', 'e153deb813ed', 'c6bbe08f2736',\\n       '09886998dc28', '5b5226ac7bac',\\n       ...\\n       '11449e662c07', '0de5072ee990', '726aec3373a4', '7b0018a6d3b2',\\n       'd2253e773f05', '1fa18364e089', 'ee19a5f9a850', 'c9dfdd668a12',\\n       '622e6f6ec380', '947f931d8855'],\\n      dtype='object', name='sop', length=124)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "for q in np.arange(0.00, 0.1, 0.01):\n",
    "    LABELS = []\n",
    "    PREDS = []\n",
    "\n",
    "    for study in t.StudyInstanceUID.unique():\n",
    "        sops = agg.loc[study]\n",
    "        label = agg_one.loc[study]\n",
    "        label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "        LABELS.append(label_is_pe)\n",
    "\n",
    "        prediction =  raw_pred.loc[sops]  # preds for current study\n",
    "\n",
    "        # pe pre\n",
    "        probs_pe_present = prediction.pe_present\n",
    "        probs_pe_present = calib_p(probs_pe_present)\n",
    "        pe_prob = post2_prob_pos(probs_pe_present, q=q)\n",
    "\n",
    "        print( \"mean\", np.mean(pe_prob) )\n",
    "\n",
    "        pe_prob = calib_p(pe_prob)\n",
    "\n",
    "        PREDS.append(pe_prob)\n",
    "\n",
    "        # break\n",
    "    # break\n",
    "\n",
    "    print(f\"q={q:.3f} logloss:{log_loss(LABELS, PREDS)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 後処理１ for PE_EXAM\n",
    "\n",
    "calib + percentile のみのくみあわせ === \n",
    "    比較対象 q=95.00 logloss:0.3996\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "best, per percnetile:95 calib:1 best_loss 0.3530707703227084\nbest, per percnetile:98.0 calib:0.6666666666666666 best_loss 0.32847901226601595\nbest, per percnetile:99 calib:0.5 best_loss 0.3310889169604432\nbest, per percnetile:99.5 calib:0.3333333333333333 best_loss 0.33267820359706207\nbest, per percnetile:100 calib:0.2 best_loss 0.35150403880704334\n"
    }
   ],
   "source": [
    "best = np.inf\n",
    "best_set = None\n",
    "\n",
    "# _raw_pred = raw_pred.copy()\n",
    "# _raw_pred = raw_pred_036ep3.copy()\n",
    "# _raw_pred = raw_pred_fold1_035ep2.copy()\n",
    "_raw_pred = raw_pred_fold1_035ep1.copy()\n",
    "\n",
    "# for calib_f in [1/32, 1/16, 1/10, 1/8, 1/6, 1/4, 1/2, 0.75, 1, 1.5, 2, 4]:\n",
    "#     for percentile in [60, 70, 80, 85 ,90, 93, 95, 97, 97.5, 98, 98.5,98.7, 99, 99.3, 99.5, 99.7, 99.9, 100]:\n",
    "# ===> final best: 0.37856055369366365 (0.25, 99)\n",
    "\n",
    "for percentile in [95, 98.0, 99, 99.5, 100]:\n",
    "    best_loss = np.inf\n",
    "    best_set = None\n",
    "    for calib_f in [1/16, 1/8, 1/6, 1/5, 1/4, 1/3, 1/2, 1/1.5, 1/1.2 , 1, 2, 4, 8, 16, 32, 64]:\n",
    "    # for calib_f in [1]:\n",
    "\n",
    "        LABELS = []\n",
    "        PREDS = []\n",
    "\n",
    "        for study in t.StudyInstanceUID.unique():\n",
    "            sops = agg.loc[study]\n",
    "            label = agg_one.loc[study]\n",
    "            label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "            LABELS.append(label_is_pe)\n",
    "\n",
    "            prediction =  _raw_pred.loc[sops]  # preds for current study\n",
    "\n",
    "            # pe pre\n",
    "            probs_pe_present = prediction.pe_present\n",
    "            probs_pe_present = calib_p(probs_pe_present, factor=calib_f)\n",
    "            pe_prob = np.percentile(probs_pe_present, q=percentile)\n",
    "\n",
    "            PREDS.append(pe_prob)\n",
    "        loss_val = log_loss(LABELS, PREDS)\n",
    "\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            best_set = (calib_f, percentile)\n",
    "    print(f\"best, per percnetile:{percentile} calib:{best_set[0]} best_loss {best_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" EXAM_POS/NEG の性能 (Log-loss)\n",
    "■ mdoel: exp001\n",
    "    q=95.00 logloss:0.3996   (calib none)\n",
    "\n",
    "■ model: exp010\n",
    "best, per percnetile:95 calib:1 best_loss 0.399617003382453\n",
    "best, per percnetile:98.0 calib:0.5 best_loss 0.3804158758247496\n",
    "best, per percnetile:99 calib:0.25 best_loss 0.37856055369366365   <=== BEST\n",
    "best, per percnetile:99.5 calib:0.25 best_loss 0.38425875684913247\n",
    "best, per percnetile:100 calib:0.125 best_loss 0.3985051085546535\n",
    "\n",
    "--\n",
    "!!! pe_preent モデルが良ければ、性能は高くなる. \n",
    "■ model: exp035 448サイズ\n",
    "best, per percnetile:95 calib:2 best_loss 0.3452049654271227\n",
    "best, per percnetile:98.0 calib:1 best_loss 0.31356833832865305\n",
    "best, per percnetile:99 calib:1 best_loss 0.2983743803866962   <=== BEST \n",
    "best, per percnetile:99.5 calib:0.5 best_loss 0.2983889966177321\n",
    "best, per percnetile:100 calib:0.5 best_loss 0.31009597097625147\n",
    "■ exp305, fold1 ep2\n",
    "best, per percnetile:95 calib:1 best_loss 0.3262976845896691\n",
    "best, per percnetile:98.0 calib:0.5 best_loss 0.3078599367296191\n",
    "best, per percnetile:99 calib:0.25 best_loss 0.30050548846528813   <=== BEST\n",
    "best, per percnetile:99.5 calib:0.125 best_loss 0.30615299306882665\n",
    "best, per percnetile:100 calib:0.0625 best_loss 0.32654930724030284\n",
    "■ exp 035 fold1 ep1\n",
    "best, per percnetile:95 calib:1 best_loss 0.3530707703227084\n",
    "best, per percnetile:98.0 calib:0.5 best_loss 0.33210658474255506\n",
    "best, per percnetile:99 calib:0.5 best_loss 0.3310889169604432   <=== BEST\n",
    "best, per percnetile:99.5 calib:0.25 best_loss 0.3368845933168983\n",
    "best, per percnetile:100 calib:0.25 best_loss 0.35516692952413287\n",
    "\n",
    "exp035 fold1\n",
    "pe_present (image-level) は epoch1 のほうがよいかった.\n",
    "しかし、 PE_EXAM判定は明らかに　epoch2 のほうがよい ... \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "combined: loss 0.3768648810456305\n"
    }
   ],
   "source": [
    "best = np.inf\n",
    "best_set = None\n",
    "\n",
    "\n",
    "LABELS = []\n",
    "PREDS = []\n",
    "\n",
    "for study in t.StudyInstanceUID.unique():\n",
    "    sops = agg.loc[study]\n",
    "    label = agg_one.loc[study]\n",
    "    label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "    LABELS.append(label_is_pe)\n",
    "\n",
    "    prediction =  raw_pred.loc[sops]  # preds for current study\n",
    "\n",
    "    # pe pre\n",
    "    probs_pe_present = prediction.pe_present\n",
    "\n",
    "    pe_prob1 = np.percentile(calib_p(probs_pe_present, factor=1/2), q=98)\n",
    "    pe_prob2 = np.percentile(calib_p(probs_pe_present, factor=1/4), q=99)\n",
    "    pe_prob3 = np.percentile(calib_p(probs_pe_present, factor=1/4), q=99.5)\n",
    "\n",
    "    pe_prob = (pe_prob1 + 2 * pe_prob2 + pe_prob3) / 4.0\n",
    "\n",
    "    PREDS.append(pe_prob)\n",
    "loss_val = log_loss(LABELS, PREDS)\n",
    "\n",
    "print(f\"combined: loss {loss_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linear Regression する. 結果は悪い. 真ん中 q=99 の重みが一番小さい\n",
    "featureをq=99のみにしてさえ悪い?\n",
    "\n",
    "weight合計を1にしないといけなさそう\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1.04035578]] [-1.36747889]\nloss 0.3784378614644151\n"
    }
   ],
   "source": [
    "Y = []\n",
    "X = []\n",
    "\n",
    "def prob_to_logit(prob):\n",
    "    return np.log(prob/(1-prob))\n",
    "# Q_ARR = [96, 99, 99.5]\n",
    "Q_ARR = [99]\n",
    "\n",
    "studies_all = t.StudyInstanceUID.unique()\n",
    "studies  = studies_all[: len(studies_all) // 2]\n",
    "\n",
    "# studies2 = studies_all[len(studies_all) // 2:]\n",
    "studies2 = studies_all\n",
    "\n",
    "for study in studies:\n",
    "    sops = agg.loc[study]\n",
    "    label = agg_one.loc[study]\n",
    "    label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "    Y.append(label_is_pe)\n",
    "\n",
    "    probs_pe_present = raw_pred.loc[sops].pe_present\n",
    "    X.append([prob_to_logit(np.percentile(probs_pe_present, q=q)) for q in Q_ARR])\n",
    "\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X, Y)\n",
    "print(clf.coef_, clf.intercept_)\n",
    "\n",
    "if False:  # 手動設定. これをすると、fold0全体に対してのlossが手動の結果とほぼ一致\n",
    "    clf.coef_ = np.array([[1]])\n",
    "    clf.intercept_ = np.array([ np.log(1/4) ])\n",
    "\n",
    "LABELS = []\n",
    "PREDS = []\n",
    "for study in studies2:\n",
    "    sops = agg.loc[study]\n",
    "    label = agg_one.loc[study]\n",
    "    label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "    LABELS.append(label_is_pe)\n",
    "\n",
    "    prediction =  raw_pred.loc[sops]  # preds for current study\n",
    "\n",
    "    # pe pre\n",
    "    probs_pe_present = prediction.pe_present\n",
    "    pe_prob = clf.predict_proba([[prob_to_logit(np.percentile(probs_pe_present, q=q)) for q in Q_ARR]])[0]\n",
    "\n",
    "    PREDS.append(pe_prob)\n",
    "loss_val = log_loss(LABELS, PREDS)\n",
    "print(f\"loss {loss_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.54636552, 0.14539564, 0.32995032]])"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" weight 最適化 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q_ARR = [98, 99, 99.5]に相当するものを 手動でやったとき\n",
    "combined: loss 0.3768648810456305\n",
    "\n",
    "以下でやった時\n",
    "0.376077\n",
    "x: array([ 0.47733139,  0.08806671,  0.29714744, -1.16465475])\n",
    "\n",
    "しかし、そもそもが誤差\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": " final_simplex: (array([[ 0.53036821,  0.0978519 ,  0.33016382, -1.16465475],\n       [ 0.5303684 ,  0.09785134,  0.33016424, -1.16465485],\n       [ 0.53036847,  0.09785094,  0.33016406, -1.16465466],\n       [ 0.53036894,  0.09785147,  0.33016375, -1.1646544 ],\n       [ 0.53036828,  0.0978516 ,  0.33016405, -1.16465472]]), array([0.37607725, 0.37607725, 0.37607725, 0.37607725, 0.37607725]))\n           fun: 0.3760772490070748\n       message: 'Optimization terminated successfully.'\n          nfev: 227\n           nit: 130\n        status: 0\n       success: True\n             x: array([ 0.53036821,  0.0978519 ,  0.33016382, -1.16465475])"
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "def prob_to_logit(prob):\n",
    "    return np.log(prob/(1-prob))\n",
    "def logit_to_prob(logit):\n",
    "    return 1 / (1 + np.exp(- logit))\n",
    "1.3 == prob_to_logit(logit_to_prob(1.3))\n",
    "\n",
    "# Q_ARR = [96, 99, 99.5]\n",
    "Q_ARR = [98, 99, 99.5]\n",
    "Q_LEN = len(Q_ARR)\n",
    "# Q_ARR = [99]\n",
    "\n",
    "studies_all = t.StudyInstanceUID.unique()\n",
    "\n",
    "LABELS = []\n",
    "FEATS_ARR = []\n",
    "for study in studies_all:\n",
    "    sops = agg.loc[study]\n",
    "    label = agg_one.loc[study]\n",
    "    label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "    LABELS.append(label_is_pe)\n",
    "\n",
    "    probs_pe_present = raw_pred.loc[sops].pe_present\n",
    "    feats = [prob_to_logit(np.percentile(probs_pe_present, q=q)) for q in Q_ARR]\n",
    "    FEATS_ARR.append(feats)\n",
    "\n",
    "def get_score(weight):\n",
    "    # print(\"called\")\n",
    "    PREDS = [] \n",
    "    for i in range(len(studies_all)):\n",
    "        feats = FEATS_ARR[i]\n",
    "        logit = ( np.sum(feats * weight[:Q_LEN]) / np.sum(weight[:Q_LEN]) ) + weight[Q_LEN]\n",
    "        PREDS.append( logit_to_prob(logit) )\n",
    "    return log_loss(LABELS, PREDS)\n",
    "\n",
    "weights = np.array([1/Q_LEN] * Q_LEN + [np.log(1/4)])\n",
    "from scipy.optimize import minimize\n",
    "minimize(get_score, weights,\n",
    "                       args=(),\n",
    "                       method=\"Nelder-Mead\",\n",
    "                       tol=1e-6,\n",
    "                       # options={\"maxiter\": 10}\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Right left central\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "q=60.00 logloss:0.698643776447078\nq=63.00 logloss:0.6365354999541909\nq=66.00 logloss:0.5879396129561644\nq=69.00 logloss:0.5459351137856083\nq=72.00 logloss:0.51321447134653\nq=75.00 logloss:0.4869159619202598\nq=78.00 logloss:0.46734739184806373\nq=81.00 logloss:0.45602309782309475\nq=84.00 logloss:0.4533383621932218\nq=87.00 logloss:0.46169121075914676\nq=90.00 logloss:0.4797557469032024\nq=93.00 logloss:0.5235644453652069\nq=96.00 logloss:0.6101237719455836\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e6a449f94d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStudyInstanceUID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_one\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabel_is_pe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindeterminate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_exam_for_pe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;31m# but will fail when the index is not present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;31m# see GH5667\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3512\u001b[0m         \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_wings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \"\"\"\n\u001b[0;32m-> 3514\u001b[0;31m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3515\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# POST1\n",
    "\n",
    "MEANS_IND = 0.020484822355039723\n",
    "\n",
    "#for q in [97,97.5,98, 98.5,99,99.5]:\n",
    "#for q in np.arange(98.5, 99.3, 0.1):\n",
    "for q in np.arange(60.0, 99.9, 3):\n",
    "# for q in [98, 98.9]:\n",
    "\n",
    "    LABELS = []\n",
    "    PREDS = []\n",
    "\n",
    "    for study in t.StudyInstanceUID.unique():\n",
    "        sops = agg.loc[study]\n",
    "        label = agg_one.loc[study]\n",
    "        label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "        LABELS.append(label_is_pe)\n",
    "\n",
    "        prediction =  raw_pred.loc[sops]  # preds for current study\n",
    "\n",
    "        # pe pre\n",
    "        probs_pe_present = prediction.pe_present\n",
    "        probs_pe_present = calib_p(probs_pe_present)\n",
    "        pe_prob = post1(probs_pe_present, q=q)\n",
    "        PREDS.append(pe_prob)\n",
    "\n",
    "    print(f\"q={q:.2f} logloss:{log_loss(LABELS, PREDS)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "q=98.00 logloss:0.383646086091538\nRIGHT\n    now  logloss:0.3451702421090064\n    past logloss:0.3617282748788149\n    base logloss:0.5762224411886869\nRIGHT\n   logloss:0.3214743942633246\n   logloss:0.3394795618701709\n   logloss:0.5300883358743675\nCENTRAL\n   logloss:0.1386441131671042\n   logloss:0.15336295710202394\n   logloss:0.23192769500092492\nq=98.90 logloss:0.374433233989411\nRIGHT\n    now  logloss:0.3451702421090064\n    past logloss:0.35746662291195486\n    base logloss:0.5762224411886869\nRIGHT\n   logloss:0.3214743942633246\n   logloss:0.3401054436957059\n   logloss:0.5300883358743675\nCENTRAL\n   logloss:0.1386441131671042\n   logloss:0.15980939159137056\n   logloss:0.23192769500092492\n"
    }
   ],
   "source": [
    "MEANS_IND = 0.020484822355039723\n",
    "\n",
    "#for q in [97,97.5,98, 98.5,99,99.5]:\n",
    "#for q in np.arange(98.5, 99.3, 0.1):\n",
    "#for q in np.arange(90.0, 99.9, 1):\n",
    "for q in [98, 98.9]:\n",
    "\n",
    "    LABELS = []\n",
    "    PREDS = []\n",
    "    LABELS_RIGHT = []\n",
    "    PREDS_RIGHT = []\n",
    "    PREDS_RIGHT2 = []\n",
    "    LABELS_LEFT= []\n",
    "    PREDS_LEFT = []\n",
    "    PREDS_LEFT2 = []\n",
    "    LABELS_CENT = []\n",
    "    PREDS_CENT = []\n",
    "    PREDS_CENT2 = []\n",
    "\n",
    "    for study in t.StudyInstanceUID.unique():\n",
    "        sops = agg.loc[study]\n",
    "        label = agg_one.loc[study]\n",
    "        label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "        LABELS.append(label_is_pe)\n",
    "\n",
    "        LABELS_RIGHT.append(label.rightsided_pe)\n",
    "        LABELS_LEFT.append(label.leftsided_pe)\n",
    "        LABELS_CENT.append(label.central_pe)\n",
    "\n",
    "        prediction =  raw_pred.loc[sops]  # preds for current study\n",
    "        # pe pre\n",
    "        probs_pe_present = prediction.pe_present_on_image\n",
    "        pe_prob = post1(probs_pe_present, q=q)\n",
    "        PREDS.append(pe_prob)\n",
    "\n",
    "        ### rightsided\n",
    "        ave_right = np.clip( np.sum( prediction.rightsided_pe ) / np.sum( prediction.pe_present_on_image ), 0, 1)\n",
    "        ave_left  = np.clip( np.sum( prediction.leftsided_pe )  / np.sum( prediction.pe_present_on_image ), 0, 1)\n",
    "        ave_cent  = np.clip( np.sum( prediction.central_pe )    / np.sum( prediction.pe_present_on_image ), 0, 1)\n",
    "\n",
    "        if 0:\n",
    "            PREDS_RIGHT.append( (1-MEANS_IND) * pe_prob *  ave_right)\n",
    "            PREDS_LEFT.append ( (1-MEANS_IND) * pe_prob *  ave_left)\n",
    "            PREDS_CENT.append ( (1-MEANS_IND) * pe_prob *  ave_cent)\n",
    "        elif 0:\n",
    "            PREDS_RIGHT.append( pe_prob *  ave_right)\n",
    "            PREDS_LEFT.append ( pe_prob *  ave_left)\n",
    "            PREDS_CENT.append ( pe_prob *  ave_cent)\n",
    "        elif 0:\n",
    "            PREDS_RIGHT.append( (1-MEANS_IND) * np.percentile( prediction.rightsided_pe, 99 ) )\n",
    "            PREDS_LEFT .append( (1-MEANS_IND) * np.percentile( prediction.leftsided_pe, 99 ) )\n",
    "            PREDS_CENT .append( (1-MEANS_IND) * np.percentile( prediction.central_pe, 99 ) )\n",
    "        elif 1:\n",
    "            PREDS_RIGHT.append( np.percentile( prediction.rightsided_pe, 99 ) * 1.15 )\n",
    "            PREDS_LEFT .append( np.percentile( prediction.leftsided_pe, 99 )  * 1.15 )\n",
    "            PREDS_CENT .append( np.percentile( prediction.central_pe, 99 )    * 1.15 )\n",
    "\n",
    "        PREDS_RIGHT2.append( pe_prob * 0.849707702540123 + (1-pe_prob) * 0 )\n",
    "        PREDS_LEFT2.append ( pe_prob * 0.6957545475146886 + (1-pe_prob) * 0 )\n",
    "        PREDS_CENT2.append ( pe_prob * 0.1796915446534345 + (1-pe_prob) * 0 )\n",
    "\n",
    "        # print(study, label_is_pe, pe_prob)\n",
    "\n",
    "    print(f\"q={q:.2f} logloss:{log_loss(LABELS, PREDS)}\")\n",
    "\n",
    "    print(\"RIGHT\")\n",
    "    print(f\"    now  logloss:{log_loss(LABELS_RIGHT, PREDS_RIGHT)}\")\n",
    "    print(f\"    past logloss:{log_loss(LABELS_RIGHT, PREDS_RIGHT2)}\")\n",
    "    print(f\"    base logloss:{log_loss(LABELS_RIGHT, len(LABELS_RIGHT)*[np.mean(LABELS_RIGHT)] )}\")\n",
    "\n",
    "    print(\"LEFT\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_LEFT, PREDS_LEFT)}\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_LEFT, PREDS_LEFT2)}\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_LEFT, len(LABELS_LEFT)*[np.mean(LABELS_LEFT)] )}\")\n",
    "\n",
    "    print(\"CENTRAL\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_CENT, PREDS_CENT)}\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_CENT, PREDS_CENT2)}\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_CENT, len(LABELS_CENT)*[np.mean(LABELS_CENT)] )}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.4547570238934727"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "log_loss(LABELS, PREDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEANS_IND = 0.020484822355039723\n",
    "\n",
    "#for q in [97,97.5,98, 98.5,99,99.5]:\n",
    "#for q in np.arange(98.5, 99.3, 0.1):\n",
    "#for q in np.arange(90.0, 99.9, 1):\n",
    "for q in [98.9]:\n",
    "\n",
    "    LABELS = []\n",
    "    PREDS = []\n",
    "    LABELS_RIGHT = []\n",
    "    PREDS_RIGHT = []\n",
    "    PREDS_RIGHT2 = []\n",
    "    LABELS_LEFT= []\n",
    "    PREDS_LEFT = []\n",
    "    PREDS_LEFT2 = []\n",
    "    LABELS_CENT = []\n",
    "    PREDS_CENT = []\n",
    "    PREDS_CENT2 = []\n",
    "\n",
    "    for study in t.StudyInstanceUID.unique():\n",
    "        sops = agg.loc[study]\n",
    "        label = agg_one.loc[study]\n",
    "        label_is_pe = int((not label.indeterminate) and (not label.negative_exam_for_pe))\n",
    "        LABELS.append(label_is_pe)\n",
    "\n",
    "        LABELS_RIGHT.append(label.rightsided_pe)\n",
    "        LABELS_LEFT.append(label.leftsided_pe)\n",
    "        LABELS_CENT.append(label.central_pe)\n",
    "\n",
    "        prediction =  raw_pred.loc[sops]  # preds for current study\n",
    "        # pe pre\n",
    "        probs_pe_present = prediction.pe_present_on_image\n",
    "        pe_prob = post1(probs_pe_present, q=q)\n",
    "        PREDS.append(pe_prob)\n",
    "\n",
    "        ### rightsided\n",
    "        ave_right = np.clip( np.sum( prediction.rightsided_pe ) / np.sum( prediction.pe_present_on_image ), 0, 1)\n",
    "        ave_left  = np.clip( np.sum( prediction.leftsided_pe )  / np.sum( prediction.pe_present_on_image ), 0, 1)\n",
    "        ave_cent  = np.clip( np.sum( prediction.central_pe )    / np.sum( prediction.pe_present_on_image ), 0, 1)\n",
    "        # print(ave_right, label_is_right)\n",
    "        PREDS_RIGHT.append( (1-MEANS_IND) * pe_prob *  ave_right)\n",
    "        PREDS_LEFT.append( (1-MEANS_IND) * pe_prob *  ave_left)\n",
    "        PREDS_CENT.append( (1-MEANS_IND) * pe_prob *  ave_cent)\n",
    "\n",
    "        PREDS_RIGHT2.append( pe_prob * 0.849707702540123 + (1-pe_prob) * 0 )\n",
    "        PREDS_LEFT2.append( pe_prob * 0.6957545475146886 + (1-pe_prob) * 0 )\n",
    "        PREDS_CENT2.append( pe_prob * 0.1796915446534345 + (1-pe_prob) * 0 )\n",
    "\n",
    "        # print(study, label_is_pe, pe_prob)\n",
    "\n",
    "    print(f\"q={q:.2f} logloss:{log_loss(LABELS, PREDS)}\")\n",
    "\n",
    "    print(f\"q={q:.2f} rifht now  logloss:{log_loss(LABELS_RIGHT, PREDS_RIGHT)}\")\n",
    "    print(f\"q={q:.2f} right past logloss:{log_loss(LABELS_RIGHT, PREDS_RIGHT2)}\")\n",
    "    print(f\"q={q:.2f} super base logloss:{log_loss(LABELS_RIGHT, len(LABELS_RIGHT)*[np.mean(LABELS_RIGHT)] )}\")\n",
    "\n",
    "    print(\"RIGHT\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_RIGHT, PREDS_RIGHT)}\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_RIGHT, PREDS_RIGHT2)}\")\n",
    "    print(f\"   logloss:{log_loss(LABELS_RIGHT, len(LABELS_RIGHT)*[np.mean(LABELS_RIGHT)] )}\")\n",
    "\n",
    "    print(f\"q={q:.2f} rifht now  logloss:{log_loss(LABELS_RIGHT, PREDS_RIGHT)}\")\n",
    "    print(f\"q={q:.2f} right past logloss:{log_loss(LABELS_RIGHT, PREDS_RIGHT2)}\")\n",
    "    print(f\"q={q:.2f} super base logloss:{log_loss(LABELS_RIGHT, len(LABELS_RIGHT)*[np.mean(LABELS_RIGHT)] )}\")\n"
   ]
  }
 ]
}